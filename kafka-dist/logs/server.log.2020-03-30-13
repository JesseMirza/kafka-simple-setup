[2020-03-30 13:34:12,918] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:34:13,780] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:34:13,782] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:34:13,785] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:34:13,836] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:13,857] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,859] INFO Client environment:host.name=1beda67ba456 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,860] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,864] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,865] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,867] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,869] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,870] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,871] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,872] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,874] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,877] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,878] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,880] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,884] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:13,916] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:13,930] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:13,938] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:13,974] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100002f3cfa0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:13,986] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:14,533] INFO Cluster ID = JEMic8RNSyen0cJr2PZEkw (kafka.server.KafkaServer)
[2020-03-30 13:34:14,539] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:34:14,695] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:34:14,719] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:34:14,786] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:14,788] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:14,790] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:14,832] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-03-30 13:34:14,844] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:34:14,866] INFO Logs loading complete in 21 ms. (kafka.log.LogManager)
[2020-03-30 13:34:14,901] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:34:14,906] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:34:15,543] INFO Awaiting socket connections on kafka1.kafkanet:9092. (kafka.network.Acceptor)
[2020-03-30 13:34:15,597] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:34:15,598] INFO Awaiting socket connections on kafka1.kafkanet:9093. (kafka.network.Acceptor)
[2020-03-30 13:34:16,188] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9093,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:34:16,191] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:34:16,238] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,242] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,245] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,246] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,289] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:34:16,420] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:34:16,456] INFO Stat of the created znode at /brokers/ids/1 is: 99,99,1585575256446,1585575256446,1,0,0,72057796924407808,214,0,99
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:34:16,460] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 99 (kafka.zk.KafkaZkClient)
[2020-03-30 13:34:16,465] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:34:16,592] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,600] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,602] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:16,679] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:34:16,682] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:34:16,709] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:34:16,738] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:34:16,836] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:34:16,851] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:34:16,853] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:34:17,000] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:17,002] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3e34ace1 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:17,018] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:17,019] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:17,022] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:17,028] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100002f3cfa0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:17,031] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:17,170] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:17,176] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:17,280] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:17,343] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:34:17,370] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:34:17,389] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:34:17,390] INFO Kafka startTimeMs: 1585575257348 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:34:17,394] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-03-30 13:34:28,883] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:34:28,887] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:34:28,910] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:34:29,002] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:34:29,019] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,022] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,022] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,025] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:34:29,063] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:34:29,067] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:34:29,080] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:34:29,085] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:34:29,088] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,090] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,090] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,092] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,094] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,095] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:34:29,097] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:29,106] INFO EventThread shut down for session: 0x100002f3cfa0001 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:29,106] INFO Session: 0x100002f3cfa0001 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:29,110] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:29,112] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,306] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,307] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,314] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:34:29,318] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:34:29,330] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:34:29,332] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:34:29,341] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:34:29,341] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:34:29,345] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:34:29,347] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:34:29,351] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,507] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,509] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,512] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,710] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,711] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,714] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:34:29,717] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:34:29,718] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:34:29,720] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:34:29,720] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:34:29,723] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:34:29,728] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:34:29,729] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:34:29,731] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:34:29,732] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,749] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,749] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,751] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,950] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,950] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:29,952] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,150] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,150] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,152] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,350] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,350] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:34:30,358] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:34:30,361] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:34:30,406] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:34:30,458] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:30,468] INFO EventThread shut down for session: 0x100002f3cfa0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:34:30,468] INFO Session: 0x100002f3cfa0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:34:30,473] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:34:30,475] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:30,793] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:30,794] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:30,796] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:31,795] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:31,795] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:31,800] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:32,799] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:32,799] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:34:32,805] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:34:32,849] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:34:32,862] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:42:41,381] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:42:42,260] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:42:42,262] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:42:42,265] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:42:42,312] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:42,334] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,336] INFO Client environment:host.name=22f93536daac (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,337] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,338] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,340] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,341] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,343] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,344] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,345] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,347] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,349] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,351] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,354] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,357] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,362] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,369] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:42,414] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:42,414] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:42,432] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:42,486] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000037001f0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:42,501] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:43,029] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:42:43,036] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:42:43,190] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:42:43,216] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:42:43,282] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:42:43,284] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:42:43,290] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:42:43,334] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-03-30 13:42:43,345] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:42:43,374] INFO Logs loading complete in 28 ms. (kafka.log.LogManager)
[2020-03-30 13:42:43,408] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:42:43,423] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:42:44,085] INFO Awaiting socket connections on kafka1.kafkanet:9092. (kafka.network.Acceptor)
[2020-03-30 13:42:44,139] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:42:44,142] INFO Awaiting socket connections on kafka1.kafkanet:9093. (kafka.network.Acceptor)
[2020-03-30 13:42:44,779] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9093,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:42:44,787] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:42:44,832] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:44,835] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:44,840] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:44,842] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:44,873] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:42:44,928] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:42:44,975] INFO Stat of the created znode at /brokers/ids/1 is: 24,24,1585575764951,1585575764951,1,0,0,72057830263160832,214,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:42:44,978] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-30 13:42:44,989] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:42:45,128] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:45,140] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:45,144] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:42:45,181] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-30 13:42:45,184] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:42:45,188] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:42:45,223] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 34 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:42:45,252] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:42:45,354] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:42:45,360] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:42:45,372] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:42:45,493] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:45,494] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@62dae540 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:42:45,508] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:45,513] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:45,523] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:45,544] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000037001f0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:42:45,546] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:42:45,681] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:42:45,687] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:42:45,844] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:42:45,897] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:42:45,925] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:42:45,930] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:42:45,933] INFO Kafka startTimeMs: 1585575765899 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:42:45,945] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-03-30 13:48:21,079] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:48:21,083] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:48:21,099] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:48:21,208] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:48:21,220] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,223] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,223] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,227] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:48:21,265] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:48:21,268] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:48:21,274] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:48:21,280] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:48:21,283] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,284] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,286] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,287] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,289] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,289] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:21,293] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:21,303] INFO EventThread shut down for session: 0x1000037001f0001 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:21,305] INFO Session: 0x1000037001f0001 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:21,308] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:21,310] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,460] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,460] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,468] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:21,474] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:48:21,476] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:48:21,477] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:48:21,479] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:48:21,479] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:48:21,481] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:21,483] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:21,486] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,665] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,665] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,669] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,866] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,866] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:21,870] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:21,872] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:48:21,874] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:48:21,875] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:48:21,875] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:48:21,878] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:48:21,881] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:48:21,883] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:48:21,884] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:48:21,886] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,069] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,070] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,074] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,272] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,272] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,275] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,475] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,475] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,479] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,677] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,677] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:22,685] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:48:22,688] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:48:22,736] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:48:22,776] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:22,784] INFO EventThread shut down for session: 0x1000037001f0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:22,784] INFO Session: 0x1000037001f0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:22,786] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:22,788] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:23,729] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:23,729] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:23,733] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:24,731] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:24,731] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:24,734] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:25,732] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:25,733] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:25,738] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:48:25,798] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:48:25,803] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:48:34,171] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:48:34,357] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:48:35,452] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:48:35,456] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:48:35,471] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:48:35,510] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:48:35,513] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:48:35,515] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:48:35,539] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:35,567] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,568] INFO Client environment:host.name=55e3b4f557bf (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,570] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,572] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,574] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:35,574] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,579] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,581] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,582] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,584] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,585] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,586] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,587] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,589] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,591] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,593] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,596] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,606] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,608] INFO Client environment:host.name=22f93536daac (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,610] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,611] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,614] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,615] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,619] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,621] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,623] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,626] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,628] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,631] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,632] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,634] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,635] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,638] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:35,647] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:35,669] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,673] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:35,691] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,697] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,706] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,735] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100003c609a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,737] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100003c609a0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:35,746] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:35,752] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:36,396] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:48:36,408] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:48:36,410] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:48:36,702] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:48:36,706] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:48:36,765] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:48:36,781] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:48:36,940] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:36,941] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:36,943] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:36,944] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:36,953] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:36,957] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:48:37,057] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-03-30 13:48:37,064] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:48:37,076] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:48:37,084] INFO Logs loading complete in 18 ms. (kafka.log.LogManager)
[2020-03-30 13:48:37,110] INFO Logs loading complete in 32 ms. (kafka.log.LogManager)
[2020-03-30 13:48:37,132] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:48:37,150] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:48:37,160] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:48:37,184] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:48:38,128] INFO Awaiting socket connections on kafka1.kafkanet:9092. (kafka.network.Acceptor)
[2020-03-30 13:48:38,260] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:48:38,262] INFO Awaiting socket connections on kafka1.kafkanet:9093. (kafka.network.Acceptor)
[2020-03-30 13:48:38,324] INFO Awaiting socket connections on kafka2.kafkanet:9094. (kafka.network.Acceptor)
[2020-03-30 13:48:38,513] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:48:38,524] INFO Awaiting socket connections on kafka2.kafkanet:9095. (kafka.network.Acceptor)
[2020-03-30 13:48:39,719] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9093,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:48:39,722] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:48:39,860] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,862] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,862] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,863] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,885] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9095,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:48:39,888] INFO [SocketServer brokerId=2] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:48:39,956] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,957] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,967] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:39,968] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:48:39,969] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,037] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:48:40,133] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,189] INFO Stat of the created znode at /brokers/ids/1 is: 76,76,1585576120164,1585576120164,1,0,0,72057853356670977,214,0,76
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,191] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 76 (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,200] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,246] INFO Stat of the created znode at /brokers/ids/2 is: 77,77,1585576120231,1585576120231,1,0,0,72057853356670976,214,0,77
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,251] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(kafka2,9094,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka2,9095,ListenerName(SSL),SSL)), czxid (broker epoch): 77 (kafka.zk.KafkaZkClient)
[2020-03-30 13:48:40,254] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:48:40,334] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,358] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,384] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,446] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,445] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:40,453] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:40,461] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,470] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:48:40,511] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:40,513] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:48:40,547] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 92 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:48:40,552] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:48:40,594] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 67 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:48:40,629] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:48:40,707] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:40,727] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:40,731] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:40,736] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:48:40,740] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:48:40,749] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:48:40,886] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:40,887] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@62fe6067 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:40,893] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:40,893] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:40,897] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:40,905] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100003c609a0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:40,910] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:41,066] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,069] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,175] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:41,186] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@305f7627 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:48:41,196] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:41,208] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:41,218] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:41,229] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x100003c609a0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:48:41,233] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:48:41,252] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,328] INFO [SocketServer brokerId=2] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:48:41,352] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,358] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,362] INFO Kafka startTimeMs: 1585576121331 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,376] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-03-30 13:48:41,390] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,401] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,635] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:48:41,667] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:48:41,685] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,698] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,699] INFO Kafka startTimeMs: 1585576121674 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:48:41,702] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-03-30 13:51:34,016] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:51:34,020] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:51:34,033] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:51:34,058] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:51:34,043] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:51:34,069] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:51:34,271] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:51:34,286] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,292] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,295] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,298] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:51:34,312] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:51:34,349] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,352] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,352] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,364] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:51:34,378] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:51:34,381] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:51:34,398] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:51:34,422] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:51:34,430] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,438] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,438] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,444] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,447] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,447] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,450] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:34,457] INFO Session: 0x100003c609a0003 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:51:34,458] INFO EventThread shut down for session: 0x100003c609a0003 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:51:34,465] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:34,467] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,509] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:51:34,517] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:51:34,522] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:51:34,525] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,525] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,530] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:51:34,537] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:51:34,543] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:51:34,546] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,550] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,551] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,555] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:51:34,554] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:51:34,559] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:51:34,561] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,563] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,563] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,563] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,567] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,568] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,569] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:51:34,572] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:34,578] INFO EventThread shut down for session: 0x100003c609a0002 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:51:34,579] INFO Session: 0x100003c609a0002 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:51:34,585] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:34,596] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,725] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,726] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,727] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,727] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,731] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,745] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:51:34,748] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:51:34,749] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:51:34,750] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,753] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,756] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:51:34,758] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:51:34,761] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:51:34,763] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,930] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,930] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,931] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,932] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,936] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:34,937] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:51:34,940] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:51:34,941] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:34,942] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:34,943] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:34,945] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:51:34,948] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:51:34,950] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:51:34,951] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:51:34,952] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,133] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,133] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,138] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,141] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,143] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:51:35,146] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:51:35,147] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:35,142] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,149] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:35,149] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:51:35,151] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:51:35,154] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:51:35,157] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:51:35,158] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:51:35,159] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,338] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,338] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,343] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,338] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,340] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,346] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,541] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,540] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,541] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,540] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,547] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,545] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,741] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,742] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,744] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,746] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,747] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,753] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:51:35,755] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:51:35,802] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:51:35,848] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:35,855] INFO Session: 0x100003c609a0001 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:51:35,856] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:35,860] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:35,870] INFO EventThread shut down for session: 0x100003c609a0001 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:51:35,942] INFO [ExpirationReaper-2-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,943] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:51:35,950] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:51:35,956] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:51:36,036] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (kafka2/172.18.0.4:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:51:36,060] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:51:36,145] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:36,151] INFO Session: 0x100003c609a0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:51:36,151] INFO EventThread shut down for session: 0x100003c609a0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:51:36,153] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:51:36,155] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,300] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,301] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,300] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,302] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,304] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:36,306] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,268] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,268] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,271] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,302] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,303] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,303] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,304] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,309] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:37,311] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:51:37,350] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:51:37,362] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:51:38,304] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:38,304] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:51:38,310] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:51:38,386] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:51:38,393] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:52:57,143] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:52:57,312] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:52:57,330] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:52:57,389] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:52:59,432] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:52:59,440] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:52:59,457] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:52:59,550] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:52:59,555] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:52:59,564] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,581] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:52:59,601] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,603] INFO Client environment:host.name=55e3b4f557bf (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,608] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,601] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:52:59,611] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,621] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,624] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,630] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,632] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,633] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,637] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,640] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,645] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,647] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,650] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,652] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,618] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:52:59,658] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,674] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:52:59,688] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:52:59,695] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:52:59,718] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:52:59,762] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,762] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,803] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,812] INFO Client environment:host.name=22f93536daac (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,820] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,822] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,824] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,825] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,830] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,836] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,845] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,850] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,847] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:52:59,851] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,856] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,858] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,857] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,859] INFO Client environment:host.name=83b903cf425d (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,862] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,861] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,865] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,874] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,876] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,877] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,879] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,880] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,881] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,883] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,888] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,890] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,892] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,896] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,903] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,901] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,908] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:52:59,910] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:52:59,944] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,970] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:52:59,982] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:52:59,985] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:00,011] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,018] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:00,018] INFO Client environment:host.name=3b966741bcbe (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,032] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,027] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,035] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,038] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,055] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,062] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,043] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,066] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,068] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,073] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,075] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,077] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,080] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,082] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,084] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,086] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,090] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:00,100] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,114] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,139] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,147] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:00,152] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:00,214] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:00,252] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,296] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,339] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:00,350] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:01,365] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:53:01,379] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:53:01,435] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:53:01,454] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:53:01,468] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:53:01,488] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:53:01,894] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:01,910] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:01,988] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,044] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9098,SSL://kafka2:9099
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9098,SSL://kafka2.kafkanet:9099
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server4.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server4.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,082] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,133] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9096,SSL://kafka1:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka3.kafkanet:9096,SSL://kafka3.kafkanet:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server3.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server3.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,173] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9098,SSL://kafka2:9099
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9098,SSL://kafka2.kafkanet:9099
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server4.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server4.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,200] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,237] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,241] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,315] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9096,SSL://kafka1:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka3.kafkanet:9096,SSL://kafka3.kafkanet:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server3.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server3.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:53:02,344] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,353] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,351] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,381] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,404] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,413] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,430] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:53:02,476] INFO Logs loading complete in 43 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,531] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-03-30 13:53:02,533] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:53:02,579] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,585] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:53:02,579] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,588] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:02,620] INFO Logs loading complete in 80 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,626] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,644] INFO Logs loading complete in 56 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,673] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,752] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-03-30 13:53:02,759] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,793] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,802] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:53:02,818] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,823] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,874] INFO Logs loading complete in 66 ms. (kafka.log.LogManager)
[2020-03-30 13:53:02,975] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:53:03,100] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:53:04,793] INFO Awaiting socket connections on kafka1.kafkanet:9092. (kafka.network.Acceptor)
[2020-03-30 13:53:04,943] INFO Awaiting socket connections on kafka2.kafkanet:9094. (kafka.network.Acceptor)
[2020-03-30 13:53:04,955] ERROR [KafkaServer id=4] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to kafka2.kafkanet:9098: Cannot assign requested address.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:605)
	at kafka.network.Acceptor.<init>(SocketServer.scala:481)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:253)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:222)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Cannot assign requested address
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:601)
	... 13 more
[2020-03-30 13:53:04,968] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:04,974] INFO [SocketServer brokerId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:04,994] INFO [SocketServer brokerId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:05,018] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:53:05,048] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:53:05,053] INFO Awaiting socket connections on kafka1.kafkanet:9093. (kafka.network.Acceptor)
[2020-03-30 13:53:05,211] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:53:05,216] INFO Awaiting socket connections on kafka2.kafkanet:9095. (kafka.network.Acceptor)
[2020-03-30 13:53:05,231] INFO Awaiting socket connections on kafka3.kafkanet:9096. (kafka.network.Acceptor)
[2020-03-30 13:53:05,297] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:53:05,302] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:05,313] INFO Session: 0x10000405ec00003 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:05,317] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:05,319] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,322] INFO EventThread shut down for session: 0x10000405ec00003 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:05,397] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,398] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,400] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,415] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,416] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,417] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:05,479] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : EndPoint(kafka3.kafkanet,9096,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:53:05,489] INFO Awaiting socket connections on kafka3.kafkanet:9097. (kafka.network.Acceptor)
[2020-03-30 13:53:05,518] ERROR Modification time of key store could not be obtained: /certs/server3.keystore.jks (org.apache.kafka.common.security.ssl.SslEngineBuilder)
java.nio.file.NoSuchFileException: /certs/server3.keystore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)
	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.nio.file.Files.readAttributes(Files.java:1737)
	at java.nio.file.Files.getLastModifiedTime(Files.java:2266)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.lastModifiedMs(SslEngineBuilder.java:295)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.<init>(SslEngineBuilder.java:272)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createKeystore(SslEngineBuilder.java:170)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:93)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-03-30 13:53:05,549] ERROR Modification time of key store could not be obtained: /certs/server3.truststore.jks (org.apache.kafka.common.security.ssl.SslEngineBuilder)
java.nio.file.NoSuchFileException: /certs/server3.truststore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)
	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.nio.file.Files.readAttributes(Files.java:1737)
	at java.nio.file.Files.getLastModifiedTime(Files.java:2266)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.lastModifiedMs(SslEngineBuilder.java:295)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.<init>(SslEngineBuilder.java:272)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createTruststore(SslEngineBuilder.java:179)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:98)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-03-30 13:53:05,792] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:73)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createSSLContext(SslEngineBuilder.java:160)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:102)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	... 18 more
Caused by: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.load(SslEngineBuilder.java:289)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createSSLContext(SslEngineBuilder.java:142)
	... 21 more
Caused by: java.nio.file.NoSuchFileException: /certs/server3.keystore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.load(SslEngineBuilder.java:282)
	... 22 more
[2020-03-30 13:53:05,803] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:05,807] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:05,855] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:05,912] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:53:06,099] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:53:06,105] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:06,129] INFO EventThread shut down for session: 0x10000405ec00001 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:06,132] INFO Session: 0x10000405ec00001 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:06,150] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:06,152] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,414] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,415] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,421] INFO [SocketServer brokerId=4] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:53:06,601] INFO [SocketServer brokerId=4] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:53:06,611] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,611] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,622] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:06,667] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:53:06,681] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-03-30 13:53:06,714] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:07,101] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9093,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:53:07,105] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:53:07,164] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9095,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:53:07,193] INFO [SocketServer brokerId=2] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:53:07,318] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,321] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,344] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,349] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,349] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,378] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,398] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,378] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:07,509] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:07,549] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:07,590] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:07,592] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:07,596] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:07,613] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:07,615] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:07,620] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:53:07,784] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:53:07,794] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,819] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,833] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:53:07,841] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-03-30 13:53:07,936] INFO Stat of the created znode at /brokers/ids/1 is: 176,176,1585576387882,1585576387882,1,0,0,72057870505476098,214,0,176
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,948] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 176 (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,946] INFO Stat of the created znode at /brokers/ids/2 is: 177,177,1585576387904,1585576387904,1,0,0,72057870505476096,214,0,177
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,951] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(kafka2,9094,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka2,9095,ListenerName(SSL),SSL)), czxid (broker epoch): 177 (kafka.zk.KafkaZkClient)
[2020-03-30 13:53:07,971] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:08,122] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,143] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,143] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,163] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,166] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,172] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:08,286] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:08,305] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:08,331] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:08,357] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:08,469] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 100 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:53:08,556] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 241 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:53:08,580] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:53:08,738] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:53:08,830] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:08,854] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:08,868] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:09,004] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:09,021] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,022] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4de41af9 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:09,042] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:09,040] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,048] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,058] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,064] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:09,066] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,068] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,291] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:09,294] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:09,449] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,455] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@47404bea (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:09,482] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,482] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,486] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,501] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x10000405ec00005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:09,504] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:09,510] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:09,599] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:53:09,709] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:09,712] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:09,714] INFO Kafka startTimeMs: 1585576389658 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:09,732] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-03-30 13:53:09,839] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:09,858] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:10,079] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:10,112] INFO [SocketServer brokerId=2] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:53:10,134] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:10,138] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:10,139] INFO Kafka startTimeMs: 1585576390115 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:53:10,142] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-03-30 13:53:52,419] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:53:52,448] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:53:52,454] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:52,463] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:53:52,497] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:53:52,500] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:53:52,628] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:53:52,647] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,652] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,656] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,663] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:52,684] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:53:52,696] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,703] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,706] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,714] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:52,742] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:52,755] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:53:52,764] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:53:52,783] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:53:52,786] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,789] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,789] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,793] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,795] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,795] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,799] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:52,808] INFO Session: 0x10000405ec00005 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:52,809] INFO EventThread shut down for session: 0x10000405ec00005 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:52,811] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:52,816] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:52,828] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:52,829] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:53:52,828] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:52,833] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:52,837] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 4000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:53:52,843] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:53:52,844] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:52,851] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:52,853] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:52,855] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:52,858] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:52,862] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:52,872] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:53:52,882] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:53:52,889] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:53:52,892] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,896] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,896] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,898] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,900] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,900] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:53:52,902] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:52,916] INFO EventThread shut down for session: 0x10000405ec00004 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:52,916] INFO Session: 0x10000405ec00004 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:52,920] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:52,921] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,028] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,029] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,030] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,032] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,028] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,036] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:53,041] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 3000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:53:53,044] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:53:53,045] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:53,047] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:53,047] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:53:53,050] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:53:53,053] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:53,055] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,232] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,232] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,233] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,237] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:53,237] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,234] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,242] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:53:53,243] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,245] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,245] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,248] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:53:53,255] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:53:53,257] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:53:53,258] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:53:53,259] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,336] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,337] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,340] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,432] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,432] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,434] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,434] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,439] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,439] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:53:53,444] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:53:53,447] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,451] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,451] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:53:53,454] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:53:53,457] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:53:53,459] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:53:53,461] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:53:53,463] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,537] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,537] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,539] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,605] INFO [ExpirationReaper-2-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,605] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,612] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:53:53,614] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:53:53,632] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,632] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,638] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,665] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:53:53,711] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:53,727] INFO EventThread shut down for session: 0x10000405ec00000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:53,728] INFO Session: 0x10000405ec00000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:53,733] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:53,736] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:53,828] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka1/172.18.0.4:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:53:53,834] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,835] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,835] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:53,936] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka1/172.18.0.4:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:53:54,034] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:54,034] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:54,039] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:54,041] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka1/172.18.0.4:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:53:54,146] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka1/172.18.0.4:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:53:54,237] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:54,237] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:53:54,246] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:53:54,249] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:53:54,250] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka1/172.18.0.4:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:53:54,287] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:53:54,316] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:54,323] INFO Session: 0x10000405ec00002 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:53:54,325] INFO EventThread shut down for session: 0x10000405ec00002 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:53:54,325] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:53:54,328] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,400] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,400] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,404] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,430] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,430] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:54,433] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,307] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,307] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,310] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,400] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,402] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:55,406] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:53:55,460] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:53:55,466] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:53:56,309] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:56,309] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:56,312] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:57,314] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:57,314] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:53:57,319] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:53:57,368] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:53:57,375] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:55:26,526] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:55:26,722] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:55:27,012] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:55:27,288] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-30 13:55:28,768] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:55:28,781] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:55:28,787] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:55:29,039] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,061] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,072] INFO Client environment:host.name=83b903cf425d (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,074] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,076] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,087] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,095] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,097] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,098] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,100] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,101] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,103] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,104] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,106] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,107] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,111] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,118] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,194] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,246] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,282] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,325] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:55:29,339] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,346] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:55:29,367] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,400] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:55:29,418] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:55:29,439] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:55:29,473] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:55:29,506] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,535] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,543] INFO Client environment:host.name=3b966741bcbe (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,546] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,548] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,551] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,554] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,557] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,558] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,560] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,562] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,563] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,565] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,567] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,569] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,570] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,579] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,649] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,658] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,678] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,693] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,694] INFO Client environment:host.name=22f93536daac (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,697] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,699] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,704] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,710] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,718] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,734] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,735] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,740] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,743] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,746] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,748] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,757] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,758] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,760] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,769] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:29,794] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,818] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,877] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:29,920] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,940] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,961] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:29,989] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:30,220] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:55:30,224] INFO starting (kafka.server.KafkaServer)
[2020-03-30 13:55:30,232] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-03-30 13:55:30,414] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:30,469] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,482] INFO Client environment:host.name=55e3b4f557bf (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,484] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,486] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,489] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,492] INFO Client environment:java.class.path=/app/bin/../libs/activation-1.1.1.jar:/app/bin/../libs/aopalliance-repackaged-2.5.0.jar:/app/bin/../libs/argparse4j-0.7.0.jar:/app/bin/../libs/audience-annotations-0.5.0.jar:/app/bin/../libs/commons-lang3-3.8.1.jar:/app/bin/../libs/connect-api-2.3.0.jar:/app/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/app/bin/../libs/connect-file-2.3.0.jar:/app/bin/../libs/connect-json-2.3.0.jar:/app/bin/../libs/connect-runtime-2.3.0.jar:/app/bin/../libs/connect-transforms-2.3.0.jar:/app/bin/../libs/guava-20.0.jar:/app/bin/../libs/hk2-api-2.5.0.jar:/app/bin/../libs/hk2-locator-2.5.0.jar:/app/bin/../libs/hk2-utils-2.5.0.jar:/app/bin/../libs/jackson-annotations-2.9.9.jar:/app/bin/../libs/jackson-core-2.9.9.jar:/app/bin/../libs/jackson-databind-2.9.9.jar:/app/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/app/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/app/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/app/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/app/bin/../libs/jackson-module-paranamer-2.9.9.jar:/app/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/app/bin/../libs/jakarta.annotation-api-1.3.4.jar:/app/bin/../libs/jakarta.inject-2.5.0.jar:/app/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/app/bin/../libs/javassist-3.22.0-CR2.jar:/app/bin/../libs/javax.servlet-api-3.1.0.jar:/app/bin/../libs/javax.ws.rs-api-2.1.1.jar:/app/bin/../libs/jaxb-api-2.3.0.jar:/app/bin/../libs/jersey-client-2.28.jar:/app/bin/../libs/jersey-common-2.28.jar:/app/bin/../libs/jersey-container-servlet-2.28.jar:/app/bin/../libs/jersey-container-servlet-core-2.28.jar:/app/bin/../libs/jersey-hk2-2.28.jar:/app/bin/../libs/jersey-media-jaxb-2.28.jar:/app/bin/../libs/jersey-server-2.28.jar:/app/bin/../libs/jetty-client-9.4.18.v20190429.jar:/app/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/app/bin/../libs/jetty-http-9.4.18.v20190429.jar:/app/bin/../libs/jetty-io-9.4.18.v20190429.jar:/app/bin/../libs/jetty-security-9.4.18.v20190429.jar:/app/bin/../libs/jetty-server-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/app/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/app/bin/../libs/jetty-util-9.4.18.v20190429.jar:/app/bin/../libs/jopt-simple-5.0.4.jar:/app/bin/../libs/jsr305-3.0.2.jar:/app/bin/../libs/kafka-clients-2.3.0.jar:/app/bin/../libs/kafka-log4j-appender-2.3.0.jar:/app/bin/../libs/kafka-streams-2.3.0.jar:/app/bin/../libs/kafka-streams-examples-2.3.0.jar:/app/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/app/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/app/bin/../libs/kafka-tools-2.3.0.jar:/app/bin/../libs/kafka_2.12-2.3.0-sources.jar:/app/bin/../libs/kafka_2.12-2.3.0.jar:/app/bin/../libs/log4j-1.2.17.jar:/app/bin/../libs/lz4-java-1.6.0.jar:/app/bin/../libs/maven-artifact-3.6.1.jar:/app/bin/../libs/metrics-core-2.2.0.jar:/app/bin/../libs/osgi-resource-locator-1.0.1.jar:/app/bin/../libs/paranamer-2.8.jar:/app/bin/../libs/plexus-utils-3.2.0.jar:/app/bin/../libs/reflections-0.9.11.jar:/app/bin/../libs/rocksdbjni-5.18.3.jar:/app/bin/../libs/scala-library-2.12.8.jar:/app/bin/../libs/scala-logging_2.12-3.9.0.jar:/app/bin/../libs/scala-reflect-2.12.8.jar:/app/bin/../libs/slf4j-api-1.7.26.jar:/app/bin/../libs/slf4j-log4j12-1.7.26.jar:/app/bin/../libs/snappy-java-1.1.7.3.jar:/app/bin/../libs/spotbugs-annotations-3.1.9.jar:/app/bin/../libs/validation-api-2.0.1.Final.jar:/app/bin/../libs/zkclient-0.11.jar:/app/bin/../libs/zookeeper-3.4.14.jar:/app/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,505] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,507] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,510] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,512] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,514] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,521] INFO Client environment:os.version=4.19.76-linuxkit (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,523] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,528] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,529] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,543] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@67a20f67 (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:30,657] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:30,710] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:30,755] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:30,774] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:30,798] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:31,198] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:55:31,212] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:55:31,301] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:55:31,325] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-30 13:55:31,447] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:55:31,787] INFO Cluster ID = lNnPGD-eQ9Cl1PNsGaMbyg (kafka.server.KafkaServer)
[2020-03-30 13:55:31,835] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9096,SSL://kafka1:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka3.kafkanet:9096,SSL://kafka3.kafkanet:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server3.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server3.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:31,883] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,002] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9096,SSL://kafka1:9097
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka3.kafkanet:9096,SSL://kafka3.kafkanet:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server3.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server3.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,008] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka1:9092,SSL://kafka1:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka1.kafkanet:9092,SSL://kafka1.kafkanet:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server1.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server1.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,009] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9098,SSL://kafka2:9099
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9098,SSL://kafka2.kafkanet:9099
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server4.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server4.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,182] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9098,SSL://kafka2:9099
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9098,SSL://kafka2.kafkanet:9099
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server4.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server4.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,212] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,215] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,219] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,229] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,228] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,260] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,367] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:55:32,377] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,350] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,373] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,376] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,417] INFO Logs loading complete in 48 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,424] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:55:32,479] INFO Logs loading complete in 50 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,494] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka2:9094,SSL://kafka2:9095
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://kafka2.kafkanet:9094,SSL://kafka2.kafkanet:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = required
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = 
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = /certs/server2.keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /certs/server2.truststore.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-30 13:55:32,584] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:55:32,613] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,630] INFO Logs loading complete in 42 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,640] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,663] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,724] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,727] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,762] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:55:32,784] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,784] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,784] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:32,935] INFO Loading logs. (kafka.log.LogManager)
[2020-03-30 13:55:32,971] INFO Logs loading complete in 34 ms. (kafka.log.LogManager)
[2020-03-30 13:55:33,104] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-30 13:55:33,125] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-30 13:55:34,701] ERROR [KafkaServer id=4] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to kafka2.kafkanet:9098: Cannot assign requested address.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:605)
	at kafka.network.Acceptor.<init>(SocketServer.scala:481)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:253)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:222)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Cannot assign requested address
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:601)
	... 13 more
[2020-03-30 13:55:34,739] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:55:34,748] INFO [SocketServer brokerId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:55:34,762] INFO [SocketServer brokerId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:55:34,791] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:55:34,841] INFO Awaiting socket connections on kafka3.kafkanet:9096. (kafka.network.Acceptor)
[2020-03-30 13:55:34,880] INFO Awaiting socket connections on kafka1.kafkanet:9092. (kafka.network.Acceptor)
[2020-03-30 13:55:34,996] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:55:35,001] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:35,014] INFO EventThread shut down for session: 0x1000042a8a00001 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:35,023] INFO Session: 0x1000042a8a00001 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:35,029] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:35,035] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,112] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : EndPoint(kafka3.kafkanet,9096,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:55:35,122] INFO Awaiting socket connections on kafka3.kafkanet:9097. (kafka.network.Acceptor)
[2020-03-30 13:55:35,149] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:55:35,156] INFO Awaiting socket connections on kafka1.kafkanet:9093. (kafka.network.Acceptor)
[2020-03-30 13:55:35,166] ERROR Modification time of key store could not be obtained: /certs/server3.keystore.jks (org.apache.kafka.common.security.ssl.SslEngineBuilder)
java.nio.file.NoSuchFileException: /certs/server3.keystore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)
	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.nio.file.Files.readAttributes(Files.java:1737)
	at java.nio.file.Files.getLastModifiedTime(Files.java:2266)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.lastModifiedMs(SslEngineBuilder.java:295)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.<init>(SslEngineBuilder.java:272)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createKeystore(SslEngineBuilder.java:170)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:93)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-03-30 13:55:35,228] ERROR Modification time of key store could not be obtained: /certs/server3.truststore.jks (org.apache.kafka.common.security.ssl.SslEngineBuilder)
java.nio.file.NoSuchFileException: /certs/server3.truststore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)
	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.nio.file.Files.readAttributes(Files.java:1737)
	at java.nio.file.Files.getLastModifiedTime(Files.java:2266)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.lastModifiedMs(SslEngineBuilder.java:295)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.<init>(SslEngineBuilder.java:272)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createTruststore(SslEngineBuilder.java:179)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:98)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2020-03-30 13:55:35,343] INFO Awaiting socket connections on kafka2.kafkanet:9094. (kafka.network.Acceptor)
[2020-03-30 13:55:35,382] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,383] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,385] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,406] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,407] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,411] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:35,521] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-30 13:55:35,524] INFO Awaiting socket connections on kafka2.kafkanet:9095. (kafka.network.Acceptor)
[2020-03-30 13:55:35,536] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:73)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.serverChannelBuilder(ChannelBuilders.java:85)
	at kafka.network.Processor.<init>(SocketServer.scala:726)
	at kafka.network.SocketServer.newProcessor(SocketServer.scala:367)
	at kafka.network.SocketServer.$anonfun$addDataPlaneProcessors$1(SocketServer.scala:261)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at kafka.network.SocketServer.addDataPlaneProcessors(SocketServer.scala:260)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:223)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: org.apache.kafka.common.KafkaException: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createSSLContext(SslEngineBuilder.java:160)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.<init>(SslEngineBuilder.java:102)
	at org.apache.kafka.common.security.ssl.SslFactory.configure(SslFactory.java:93)
	at org.apache.kafka.common.network.SslChannelBuilder.configure(SslChannelBuilder.java:71)
	... 18 more
Caused by: org.apache.kafka.common.KafkaException: Failed to load SSL keystore /certs/server3.keystore.jks of type JKS
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.load(SslEngineBuilder.java:289)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder.createSSLContext(SslEngineBuilder.java:142)
	... 21 more
Caused by: java.nio.file.NoSuchFileException: /certs/server3.keystore.jks
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.security.ssl.SslEngineBuilder$SecurityStore.load(SslEngineBuilder.java:282)
	... 22 more
[2020-03-30 13:55:35,551] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:55:35,558] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:55:35,610] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:55:35,675] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:55:35,802] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:55:35,817] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:35,830] INFO Session: 0x1000042a8a00000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:35,834] INFO EventThread shut down for session: 0x1000042a8a00000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:35,846] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:35,852] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,255] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,255] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,258] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,274] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,275] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,277] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,400] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,400] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:36,417] INFO [SocketServer brokerId=4] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:55:36,650] INFO [SocketServer brokerId=4] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:55:36,685] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:55:36,691] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-03-30 13:55:36,711] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:55:36,994] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(kafka1.kafkanet,9093,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:55:37,005] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:55:37,235] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,275] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:37,276] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:55:37,285] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:55:37,238] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,294] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,280] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,491] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:55:37,584] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:55:37,608] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:55:37,610] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-03-30 13:55:37,696] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:55:37,698] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(kafka2.kafkanet,9095,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[2020-03-30 13:55:37,702] INFO [SocketServer brokerId=2] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-30 13:55:37,707] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:37,774] INFO Stat of the created znode at /brokers/ids/1 is: 278,278,1585576537750,1585576537750,1,0,0,72057880334827522,214,0,278
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:37,778] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 278 (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:37,786] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,790] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,808] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,816] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:37,858] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:55:38,021] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,041] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,050] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,148] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:38,171] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:55:38,219] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:55:38,251] INFO Stat of the created znode at /brokers/ids/2 is: 280,280,1585576538184,1585576538184,1,0,0,72057880334827523,214,0,280
 (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:38,253] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(kafka2,9094,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka2,9095,ListenerName(SSL),SSL)), czxid (broker epoch): 280 (kafka.zk.KafkaZkClient)
[2020-03-30 13:55:38,390] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 169 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:55:38,538] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:55:38,542] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,558] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,564] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:55:38,676] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:55:38,718] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:55:38,819] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 102 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-30 13:55:38,832] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:55:38,882] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:55:38,878] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:55:38,891] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:55:39,034] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:55:39,053] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:55:39,067] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:55:39,264] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,272] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5778826f (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:39,291] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,292] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,296] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,311] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,315] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,350] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,354] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@47404bea (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:55:39,385] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,386] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,389] INFO Socket connection established to zookeeper/172.18.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,397] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, sessionid = 0x1000042a8a00005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:55:39,399] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:55:39,540] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,552] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,666] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,676] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,762] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,792] INFO [SocketServer brokerId=2] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:55:39,809] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:55:39,819] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,822] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,825] INFO Kafka startTimeMs: 1585576539795 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,829] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-03-30 13:55:39,934] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-03-30 13:55:39,947] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,950] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,951] INFO Kafka startTimeMs: 1585576539937 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-30 13:55:39,954] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-03-30 13:56:30,319] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:56:30,324] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:56:30,334] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-30 13:56:30,344] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2020-03-30 13:56:30,342] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:56:30,384] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-30 13:56:30,522] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:56:30,540] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,542] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,546] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,550] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:56:30,580] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-30 13:56:30,602] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,606] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,610] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,613] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:56:30,642] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:56:30,644] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:56:30,653] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:56:30,669] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-30 13:56:30,679] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:56:30,680] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:56:30,688] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,689] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,693] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,694] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,695] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,696] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,698] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-30 13:56:30,699] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:30,711] INFO EventThread shut down for session: 0x1000042a8a00005 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:56:30,712] INFO Session: 0x1000042a8a00005 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:56:30,715] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:30,717] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,721] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-30 13:56:30,724] INFO [/kafka-acl-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,725] INFO [/kafka-acl-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,726] INFO [/kafka-acl-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,728] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,729] INFO [/kafka-acl-extended-changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,729] INFO [/kafka-acl-extended-changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-30 13:56:30,733] INFO [ZooKeeperClient Simple ACL authorizer] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:30,745] INFO EventThread shut down for session: 0x1000042a8a00004 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:56:30,745] INFO Session: 0x1000042a8a00004 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:56:30,752] INFO [ZooKeeperClient Simple ACL authorizer] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:30,754] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,775] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,775] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,780] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:56:30,783] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 5000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:56:30,790] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:56:30,791] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,793] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,793] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,796] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:56:30,799] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:56:30,801] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,850] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,850] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,858] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:56:30,861] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-30 13:56:30,864] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-30 13:56:30,866] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,868] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,868] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-30 13:56:30,872] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-30 13:56:30,875] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:56:30,877] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,977] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,977] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:30,981] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,054] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,054] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,059] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,177] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,177] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,181] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:56:31,183] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:56:31,185] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,187] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,188] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,190] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:56:31,193] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:56:31,194] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:56:31,196] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:56:31,197] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,258] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,260] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,258] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,263] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,260] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,266] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-30 13:56:31,287] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2020-03-30 13:56:31,289] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,291] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,291] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-30 13:56:31,294] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:56:31,297] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-30 13:56:31,299] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:56:31,305] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-30 13:56:31,307] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,380] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,380] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,381] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,381] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,386] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,385] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,460] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,459] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,462] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,465] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,461] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,467] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,527] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,528] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,530] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,662] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,662] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,671] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:56:31,673] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:56:31,710] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:56:31,727] INFO [ExpirationReaper-2-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,727] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-30 13:56:31,736] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2020-03-30 13:56:31,741] INFO Shutting down. (kafka.log.LogManager)
[2020-03-30 13:56:31,753] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:31,760] INFO Session: 0x1000042a8a00002 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:56:31,761] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:31,762] INFO EventThread shut down for session: 0x1000042a8a00002 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:56:31,764] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:31,855] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-30 13:56:31,893] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (kafka2/172.18.0.5:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2020-03-30 13:56:31,985] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:31,998] INFO EventThread shut down for session: 0x1000042a8a00003 (org.apache.zookeeper.ClientCnxn)
[2020-03-30 13:56:31,999] INFO Session: 0x1000042a8a00003 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-30 13:56:32,001] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-30 13:56:32,003] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,290] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,290] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,294] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,831] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,831] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,834] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,849] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,849] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:32,851] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,292] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,293] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,295] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,850] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,850] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:33,855] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:56:33,908] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:56:33,916] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2020-03-30 13:56:34,298] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:34,299] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-30 13:56:34,302] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2020-03-30 13:56:34,403] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2020-03-30 13:56:34,409] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
